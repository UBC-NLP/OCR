# -*- coding: utf-8 -*-
"""Copy of Evaluating TrOCR-base-handwritten on the IAM test set.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fnyl8mci2GV9KPAW6j1WTnU9E-wMzsWE

## Set-up environment
"""


"""## Load IAM test set"""


from transformers import TrOCRProcessor
from tqdm.notebook import tqdm
from datasets import load_metric
from transformers import VisionEncoderDecoderModel
from torch.utils.data import DataLoader
from PIL import Image
from torch.utils.data import Dataset
import torch
import pandas as pd
from datasets import load_dataset
import click 

@click.command()
@click.option('--dataset_name', default='ADAB', help='Dataset name')
def main(dataset_name):
    dataset = load_dataset("/home/gagan30/scratch/arocr/AraOCR_dataset", dataset_name, split="test")
    df = pd.DataFrame(dataset)

    class IAMDataset(Dataset):
        def __init__(self, root_dir, df, processor, max_target_length=256):
            self.root_dir = root_dir
            self.df = df
            self.processor = processor
            self.max_target_length = max_target_length

        def __len__(self):
            return len(self.df)

        def __getitem__(self, idx):
            # get file name + text
            text = self.df['text'][idx]
            # some file names end with jp instead of jpg, the two lines below fix this
            # prepare image (i.e. resize + normalize)
            image = self.df['image'][idx].convert("RGB")
            pixel_values = self.processor(image, return_tensors="pt").pixel_values
            # add labels (input_ids) by encoding the text
            labels = self.processor.tokenizer(text,
                                            padding="max_length",
                                            max_length=self.max_target_length).input_ids
            # important: make sure that PAD tokens are ignored by the loss function
            labels = [label if label !=
                    self.processor.tokenizer.pad_token_id else -100 for label in labels]

            encoding = {"pixel_values": pixel_values.squeeze(),
                        "labels": torch.tensor(labels)}
            return encoding


    processor = TrOCRProcessor.from_pretrained("../models/trocr-base")
    test_dataset = IAMDataset(root_dir='',
                            df=df,
                            processor=processor)


    test_dataloader = DataLoader(test_dataset, batch_size=8)

    batch = next(iter(test_dataloader))

    for k, v in batch.items():
        print(k, v.shape)


    processor = TrOCRProcessor.from_pretrained("../models/trocr-base")

    labels = batch["labels"]
    labels[labels == -100] = processor.tokenizer.pad_token_id
    label_str = processor.batch_decode(labels, skip_special_tokens=True)
    """## Run evaluation"""


    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    model = VisionEncoderDecoderModel.from_pretrained(
        "microsoft/trocr-base-handwritten")
    model.to(device)


    cer = load_metric("cer.py")
    wer = load_metric("wer.py")


    print("Running evaluation...")

    for batch in tqdm(test_dataloader):
        # predict using generate
        pixel_values = batch["pixel_values"].to(device)
        outputs = model.generate(pixel_values)

        # decode
        pred_str = processor.batch_decode(outputs, skip_special_tokens=True)
        labels = batch["labels"]
        labels[labels == -100] = processor.tokenizer.pad_token_id
        label_str = processor.batch_decode(labels, skip_special_tokens=True)

        # add batch to metric
        cer.add_batch(predictions=pred_str, references=label_str)
        wer.add_batch(predictions=pred_str, references=label_str)

    print("Dataset: {}".format(dataset_name))
    final_score = cer.compute()
    print("Final CER: {:.2f}".format(final_score))
    final_score = wer.compute()
    print("Final WER: {:.2f}".format(final_score))

if __name__ == '__main__':
    main()
